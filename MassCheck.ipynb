{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from collections import Counter\n",
    "from helper.helper import format_number_and_round\n",
    "from preprocessing.scarpping_component import extract_component_by_images\n",
    "import os\n",
    "import pandas as pd\n",
    "import dlib\n",
    "import cv2\n",
    "from feature_extraction.poc import POC\n",
    "from feature_extraction.vektor import Vektor\n",
    "from feature_extraction.quadran import Quadran\n",
    "from preprocessing.input_to_image import get_frames_by_input_video\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk sorting natural\n",
    "import re\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split('(\\d+)', s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the result from the predictions\n",
    "def get_calculate_from_predict(list_decoded_predictions):\n",
    "    prediction_counts = Counter(list_decoded_predictions)\n",
    "    total_predictions = len(list_decoded_predictions)\n",
    "    result_prediction = None\n",
    "    most_common_count = 0\n",
    "    list_predictions = []\n",
    "\n",
    "    for category, count in prediction_counts.items():\n",
    "        percentage = (count / total_predictions) * 100\n",
    "        list_predictions.append({\n",
    "            \"name\": category,\n",
    "            \"count\": count,\n",
    "            \"percentage\": format_number_and_round(percentage)\n",
    "        })\n",
    "        if count > most_common_count:\n",
    "            most_common_count = count\n",
    "            result_prediction = category\n",
    "\n",
    "    # Sort the predictions by percentage in descending order\n",
    "    list_predictions.sort(key=lambda x: x[\"percentage\"], reverse=True)\n",
    "\n",
    "    return result_prediction, list_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and print results\n",
    "def predict_and_print_results(df, model, label_encoder, feature_columns):\n",
    "    df = df.drop(columns=feature_columns)\n",
    "    predictions = model.predict(df.values)\n",
    "    decoded_predictions = label_encoder.inverse_transform(predictions)\n",
    "    result_prediction, list_predictions = get_calculate_from_predict(decoded_predictions)\n",
    "    \n",
    "    for pred in list_predictions:\n",
    "        print(f\"Kategori: {pred['name']}, Jumlah: {pred['count']}, Persentase: {pred['percentage']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nHasil Prediksi: {result_prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ekstraksi frame dari dataset/casme_custom/Disgust/24_EP02_02f.avi dengan Total Gambar 488 berhasil. Frame rate: 200.0 FPS.\n",
      "Predictions with Nose:\n",
      "Kategori: Disgust, Jumlah: 487, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Disgust\n",
      "==================================================\n",
      "Predictions without Nose:\n",
      "Kategori: Disgust, Jumlah: 487, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Disgust\n",
      "\n",
      "##################################################\n",
      "\n",
      "Ekstraksi frame dari dataset/casme_custom/Disgust/19_EP16_02.avi dengan Total Gambar 266 berhasil. Frame rate: 200.0 FPS.\n",
      "Predictions with Nose:\n",
      "Kategori: Disgust, Jumlah: 265, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Disgust\n",
      "==================================================\n",
      "Predictions without Nose:\n",
      "Kategori: Disgust, Jumlah: 265, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Disgust\n",
      "\n",
      "##################################################\n",
      "\n",
      "Ekstraksi frame dari dataset/casme_custom/Disgust/03_EP19_08.avi dengan Total Gambar 291 berhasil. Frame rate: 200.0 FPS.\n",
      "Predictions with Nose:\n",
      "Kategori: Disgust, Jumlah: 290, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Disgust\n",
      "==================================================\n",
      "Predictions without Nose:\n",
      "Kategori: Disgust, Jumlah: 290, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Disgust\n",
      "\n",
      "##################################################\n",
      "\n",
      "Ekstraksi frame dari dataset/casme_custom/Disgust/25_EP18_04f.avi dengan Total Gambar 448 berhasil. Frame rate: 200.0 FPS.\n",
      "Predictions with Nose:\n",
      "Kategori: Disgust, Jumlah: 447, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Disgust\n",
      "==================================================\n",
      "Predictions without Nose:\n",
      "Kategori: Disgust, Jumlah: 447, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Disgust\n",
      "\n",
      "##################################################\n",
      "\n",
      "Ekstraksi frame dari dataset/casme_custom/Disgust/20_EP06_03.avi dengan Total Gambar 173 berhasil. Frame rate: 200.0 FPS.\n",
      "Predictions with Nose:\n",
      "Kategori: Disgust, Jumlah: 172, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Disgust\n",
      "==================================================\n",
      "Predictions without Nose:\n",
      "Kategori: Disgust, Jumlah: 172, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Disgust\n",
      "\n",
      "##################################################\n",
      "\n",
      "Ekstraksi frame dari dataset/casme_custom/Disgust/17_EP13_04.avi dengan Total Gambar 174 berhasil. Frame rate: 200.0 FPS.\n",
      "Predictions with Nose:\n",
      "Kategori: Disgust, Jumlah: 173, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Disgust\n",
      "==================================================\n",
      "Predictions without Nose:\n",
      "Kategori: Disgust, Jumlah: 173, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Disgust\n",
      "\n",
      "##################################################\n",
      "\n",
      "Ekstraksi frame dari dataset/casme_custom/Disgust/25_EP09_02.avi dengan Total Gambar 232 berhasil. Frame rate: 200.0 FPS.\n",
      "Predictions with Nose:\n",
      "Kategori: Disgust, Jumlah: 231, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Disgust\n",
      "==================================================\n",
      "Predictions without Nose:\n",
      "Kategori: Disgust, Jumlah: 231, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Disgust\n",
      "\n",
      "##################################################\n",
      "\n",
      "Ekstraksi frame dari dataset/casme_custom/Happiness/17_EP06_07.avi dengan Total Gambar 360 berhasil. Frame rate: 200.0 FPS.\n",
      "Predictions with Nose:\n",
      "Kategori: Happiness, Jumlah: 359, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Happiness\n",
      "==================================================\n",
      "Predictions without Nose:\n",
      "Kategori: Happiness, Jumlah: 359, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Happiness\n",
      "\n",
      "##################################################\n",
      "\n",
      "Ekstraksi frame dari dataset/casme_custom/Happiness/09_EP15_05.avi dengan Total Gambar 200 berhasil. Frame rate: 200.0 FPS.\n",
      "Predictions with Nose:\n",
      "Kategori: Happiness, Jumlah: 199, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Happiness\n",
      "==================================================\n",
      "Predictions without Nose:\n",
      "Kategori: Happiness, Jumlah: 199, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Happiness\n",
      "\n",
      "##################################################\n",
      "\n",
      "Ekstraksi frame dari dataset/casme_custom/Happiness/01_EP02_01f.avi dengan Total Gambar 290 berhasil. Frame rate: 200.0 FPS.\n",
      "Predictions with Nose:\n",
      "Kategori: Happiness, Jumlah: 289, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Happiness\n",
      "==================================================\n",
      "Predictions without Nose:\n",
      "Kategori: Happiness, Jumlah: 289, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Happiness\n",
      "\n",
      "##################################################\n",
      "\n",
      "Ekstraksi frame dari dataset/casme_custom/Happiness/05_EP03_01.avi dengan Total Gambar 218 berhasil. Frame rate: 200.0 FPS.\n",
      "Predictions with Nose:\n",
      "Kategori: Happiness, Jumlah: 217, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Happiness\n",
      "==================================================\n",
      "Predictions without Nose:\n",
      "Kategori: Happiness, Jumlah: 217, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Happiness\n",
      "\n",
      "##################################################\n",
      "\n",
      "Ekstraksi frame dari dataset/casme_custom/Happiness/14_EP09_03.avi dengan Total Gambar 51 berhasil. Frame rate: 200.0 FPS.\n",
      "Predictions with Nose:\n",
      "Kategori: Happiness, Jumlah: 50, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Happiness\n",
      "==================================================\n",
      "Predictions without Nose:\n",
      "Kategori: Happiness, Jumlah: 50, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Happiness\n",
      "\n",
      "##################################################\n",
      "\n",
      "Ekstraksi frame dari dataset/casme_custom/Happiness/06_EP01_01.avi dengan Total Gambar 236 berhasil. Frame rate: 200.0 FPS.\n",
      "Predictions with Nose:\n",
      "Kategori: Happiness, Jumlah: 235, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Happiness\n",
      "==================================================\n",
      "Predictions without Nose:\n",
      "Kategori: Happiness, Jumlah: 235, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Happiness\n",
      "\n",
      "##################################################\n",
      "\n",
      "Ekstraksi frame dari dataset/casme_custom/Happiness/09_EP05_05.avi dengan Total Gambar 169 berhasil. Frame rate: 200.0 FPS.\n",
      "Predictions with Nose:\n",
      "Kategori: Happiness, Jumlah: 168, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Happiness\n",
      "==================================================\n",
      "Predictions without Nose:\n",
      "Kategori: Happiness, Jumlah: 168, Persentase: 100.00%\n",
      "\n",
      "Hasil Prediksi: Happiness\n",
      "\n",
      "##################################################\n",
      "\n",
      "File tidak berformat .avi.\n",
      "Predictions with Nose:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Frame', 'Folder Path', 'Label'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 338\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# Predict and print results with nose\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions with Nose:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 338\u001b[0m \u001b[43mpredict_and_print_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_fitur_all\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_hidung\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_encoder_hidung\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexcept_feature_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# print garis pemisah antar hasil prediksi\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mpredict_and_print_results\u001b[0;34m(df, model, label_encoder, feature_columns)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_and_print_results\u001b[39m(df, model, label_encoder, feature_columns):\n\u001b[0;32m----> 3\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(df\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m      5\u001b[0m     decoded_predictions \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(predictions)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Frame', 'Folder Path', 'Label'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Load the models and label encoders\n",
    "model_hidung = joblib.load('output-baru-dengan-hidung/data/manhattan/knn_model_n_neighbors_3_metric_manhattan.joblib')\n",
    "label_encoder_hidung = joblib.load('output-baru-dengan-hidung/data/manhattan/label_encoder_n_neighbors_3_metric_manhattan.joblib')\n",
    "\n",
    "# Model saved to output-baru-dengan-hidung/data/euclidean/knn_model_n_neighbors_3_metric_euclidean.joblib\n",
    "# Label encoder saved to output-baru-dengan-hidung/data/euclidean/label_encoder_n_neighbors_3_metric_euclidean.joblib\n",
    "\n",
    "model_tanpa_hidung = joblib.load('output-baru-tanpa-hidung/data/manhattan/knn_model_n_neighbors_3_metric_manhattan.joblib')\n",
    "label_encoder_tanpa_hidung = joblib.load('output-baru-tanpa-hidung/data/manhattan/label_encoder_n_neighbors_3_metric_manhattan.joblib')\n",
    "\n",
    "components_setup = {\n",
    "    'mulut': {\n",
    "        'object_name': 'mouth',\n",
    "        'object_rectangle': {\"x_right\": 54, \"x_left\": 48, \"y_highest\": 52, \"y_lowest\": 57},\n",
    "        'pixel_shifting': {\"pixel_x\": 25, \"pixel_y\": 5},\n",
    "        'object_dimension': {'width': 140, 'height': 40}\n",
    "    },\n",
    "    'mata_kiri': {\n",
    "        'object_name': 'eye_left',\n",
    "        'object_rectangle': {\"x_right\": 39, \"x_left\": 36, \"y_highest\": 38, \"y_lowest\": 41},\n",
    "        'pixel_shifting': {\"pixel_x\": 25, \"pixel_y\": 25},\n",
    "        'object_dimension': {'width': 90, 'height': 55}\n",
    "    },\n",
    "    'mata_kanan': {\n",
    "        'object_name': 'eye_right',\n",
    "        'object_rectangle': {\"x_right\": 45, \"x_left\": 42, \"y_highest\": 43, \"y_lowest\": 47},\n",
    "        'pixel_shifting': {\"pixel_x\": 25, \"pixel_y\": 25},\n",
    "        'object_dimension': {'width': 90, 'height': 55}\n",
    "    },\n",
    "    'alis_kiri': {\n",
    "        'object_name': 'eyebrow_left',\n",
    "        'object_rectangle': {\"x_right\": 21, \"x_left\": 17, \"y_highest\": 18, \"y_lowest\": 21},\n",
    "        'pixel_shifting': {\"pixel_x\": 15, \"pixel_y\": 15},\n",
    "        'object_dimension': {'width': 110, 'height': 40}\n",
    "    },\n",
    "    'alis_kanan': {\n",
    "        'object_name': 'eyebrow_right',\n",
    "        'object_rectangle': {\"x_right\": 26, \"x_left\": 22, \"y_highest\": 25, \"y_lowest\": 22},\n",
    "        'pixel_shifting': {\"pixel_x\": 15, \"pixel_y\": 15},\n",
    "        'object_dimension': {'width': 110, 'height': 40}\n",
    "    },\n",
    "    'hidung_kanan': {\n",
    "        'object_name': 'nose_right',\n",
    "        'object_rectangle': {\"x_right\": 31, \"x_left\": 40, \"y_highest\": 40, \"y_lowest\": 48},\n",
    "        'pixel_shifting': {\"pixel_x\": 15, \"pixel_y\": -25},\n",
    "        'object_dimension': {'width': 70, 'height': 40}\n",
    "    },\n",
    "    'hidung_kiri': {\n",
    "        'object_name': 'nose_left',\n",
    "        'object_rectangle': {\"x_right\": 47, \"x_left\": 35, \"y_highest\": 47, \"y_lowest\": 54},\n",
    "        'pixel_shifting': {\"pixel_x\": 15, \"pixel_y\": -25},\n",
    "        'object_dimension': {'width': 70, 'height': 40}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert Video to Image\n",
    "# Path utama\n",
    "# Definisikan direktori video dan folder output\n",
    "# video_directory = 'dataset/casme_custom/Disgust/19_EP16_02.avi'\n",
    "\n",
    "base_directory = 'dataset/casme_custom'\n",
    "base_output_folder = 'output_consume_video'\n",
    "\n",
    "# Definisikan direktori video dan folder output\n",
    "# dimana didalam file casme_custom terdapat folder Disgust, Happiness, Sadness, dan Surprise\n",
    "emotion_folders = ['Disgust', 'Happiness', 'Sadness', 'Surprise']\n",
    "\n",
    "for emotion_folder in emotion_folders:\n",
    "    # Ambil semua file yang ada didalam folder emosi    \n",
    "    for filename in os.listdir(os.path.join(base_directory, emotion_folder)):\n",
    "        # Ambil path dari video\n",
    "        video_directory = os.path.join(base_directory, emotion_folder, filename)\n",
    "\n",
    "        # Bersihkan folder output jika ada dan buat folder baru\n",
    "        if os.path.exists(base_output_folder):\n",
    "            shutil.rmtree(base_output_folder)  # Hapus folder output jika sudah ada\n",
    "        os.makedirs(base_output_folder)  # Buat folder output baru\n",
    "\n",
    "        # Cek apakah file ada atau tidak\n",
    "        if video_directory.endswith(\".avi\"):\n",
    "\n",
    "            # Apakah file tersebut ada atau tidak\n",
    "            if not os.path.exists(video_directory):\n",
    "                print(\"Error: File tidak ditemukan.\")\n",
    "                exit\n",
    "            \n",
    "            # Buka video menggunakan OpenCV\n",
    "            vidcap = cv2.VideoCapture(video_directory)\n",
    "\n",
    "            # Cek apakah video berhasil dibuka\n",
    "            if not vidcap.isOpened():\n",
    "                print(\"Error: Video tidak dapat dibuka.\")\n",
    "                exit()\n",
    "\n",
    "            # Ambil frame rate dari video\n",
    "            frame_per_second = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "            # Variabel untuk menghitung nomor frame\n",
    "            count = 1\n",
    "\n",
    "            while True:\n",
    "                success, image = vidcap.read()  # Baca frame\n",
    "                if not success:\n",
    "                    break  # Jika tidak ada frame yang dibaca, keluar dari loop\n",
    "\n",
    "                # Simpan gambar ke folder output dengan nama imgX.jpg\n",
    "                img_name = f'img{count}.jpg'\n",
    "                output_path = os.path.join(base_output_folder, img_name)\n",
    "                # print(f\"Menyimpan {img_name}...\")\n",
    "                cv2.imwrite(output_path, image)\n",
    "\n",
    "                # Increment count\n",
    "                count += 1\n",
    "\n",
    "            # Tutup video\n",
    "            vidcap.release()\n",
    "            print(f\"Ekstraksi frame dari {video_directory} dengan Total Gambar {count - 1} berhasil. Frame rate: {frame_per_second} FPS.\")\n",
    "        else:\n",
    "            print(\"File tidak berformat .avi.\")\n",
    "            # stop cell execution\n",
    "            exit()\n",
    "\n",
    "\n",
    "        # Initialize variables for feature extraction\n",
    "        blockSize = 5\n",
    "        frames_data_quadran = []\n",
    "        frames_data_all_component = []\n",
    "        frames_data_quadran_column = ['sumX', 'sumY', 'Tetha', 'Magnitude', 'JumlahQuadran']\n",
    "        quadran_dimensions = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "        frames_data = {component_name: [] for component_name in components_setup}\n",
    "        total_blocks_components = {component_name: 0 for component_name in components_setup}\n",
    "        data_blocks_first_image = {component_name: None for component_name in components_setup}\n",
    "\n",
    "        # Load face detector and shape predictor\n",
    "        detector = dlib.get_frontal_face_detector()\n",
    "        predictor = dlib.shape_predictor(\"models/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "        # Hitung total blok dari masing-masing komponen lalu disetup kedalam total_blocks_components\n",
    "        for component_name, component_info in components_setup.items():\n",
    "            total_blocks_components[component_name] = int((component_info['object_dimension']['width'] / blockSize) * (component_info['object_dimension']['height'] / blockSize))\n",
    "\n",
    "        # Reset variabel setiap kali mulai looping folder baru\n",
    "        data_blocks_first_image = {component_name: None for component_name in components_setup}\n",
    "        index = {component_name: 0 for component_name in components_setup}\n",
    "\n",
    "        # looping semua file yang ada didalam\n",
    "        for filename in sorted(os.listdir(base_output_folder), key=natural_sort_key):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n",
    "\n",
    "                # Read path sesuai dengan foldername_join_basepath dijoin path dengan filename\n",
    "                image = cv2.imread(os.path.join(base_output_folder, filename))\n",
    "                # Resize image ke ukuran yang diinginkan\n",
    "                # image = cv2.resize(image, (600, 500))\n",
    "                # Cpmvert image ke grayscale\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Deteksi shape muka didalam grayscale image\n",
    "                rects = detector(gray)\n",
    "\n",
    "                if not index[component_name] == 0:\n",
    "                    # Buat variabel frames_data_all_component untuk menampung data current frame\n",
    "                    frame_data_all_component = {'Frame': f\"{index[component_name] + 1}({filename.split('.')[0]})\"}\n",
    "                    # Buat variabel frame_data_quadran untuk menampung data current frame\n",
    "                    frame_data_quadran = {'Frame': f\"{index[component_name] + 1}({filename.split('.')[0]})\"}\n",
    "\n",
    "                # Memproses rects untuk setiap bentuk wajah yang terdeteksi\n",
    "                for rect in rects:\n",
    "                    # Ambil bentuk wajah dalam bentuk shape sesuai dengan model predictor\n",
    "                    shape = predictor(gray, rect)\n",
    "                    # Memproses setiap komponen wajah\n",
    "                    for component_name, component_info in components_setup.items():\n",
    "                        # print(f\"Processing {component_name} in {filename}...\")\n",
    "                        # Inisialisasi variabel sum_data_by_quadran untuk menyimpan data hasil quadran\n",
    "                        sum_data_by_quadran = {}\n",
    "                        # Buat variabel frame_data untuk menampung data current frame\n",
    "                        frame_data = {'Frame': f\"{index[component_name] + 1}({filename.split('.')[0]})\"}\n",
    "\n",
    "                        # Looping untuk setiap atribut dalam frames_data_quadran_column\n",
    "                        for column in frames_data_quadran_column:\n",
    "                            # Inisialisasi sub-dictionary untuk setiap atribut dalam frames_data_quadran_column yang defaultnya 0\n",
    "                            sum_data_by_quadran[column] = {quadrant: 0 for quadrant in quadran_dimensions}\n",
    "\n",
    "                        # Ambil data blok image dari return fungsi extract_component_by_images\n",
    "                        data_blocks_image_current = extract_component_by_images(\n",
    "                            image=image,\n",
    "                            shape=shape,\n",
    "                            frameName=filename.split(\".\")[0],\n",
    "                            objectName=component_info['object_name'],\n",
    "                            objectRectangle=component_info['object_rectangle'],\n",
    "                            pixelShifting=component_info['pixel_shifting'],\n",
    "                            objectDimension=component_info['object_dimension']\n",
    "                        )\n",
    "                        \n",
    "                        # Ambil frame pertama dari perulangan lalu simpan di variabel dan skip (lanjutkan ke frame berikut)\n",
    "                        if data_blocks_first_image[component_name] is None:\n",
    "                            # --- Setup bagian 4qmv Dataset ---\n",
    "                            # Inisialisasi data untuk setiap blok dan setiap kuadran dengan nilai sesuai sum_data_by_quadran\n",
    "                            # for quadrant in quadran_dimensions:\n",
    "                            #     for feature in frames_data_quadran_column:\n",
    "                            #         # Buat nama kolom dengan menggunakan template yang diberikan\n",
    "                            #         column_name = f\"{component_name}_{feature}_{quadrant}\"\n",
    "                            #         # Set value sum_data_by_quadran[feature][quadrant] ke frame_data_quadran sesuai column_name nya\n",
    "                            #         frame_data_quadran[column_name] = sum_data_by_quadran[feature][quadrant]\n",
    "\n",
    "                            # --- Setup bagian Nilai Fitur Dataset ---\n",
    "                            # Inisialisasi data untuk setiap blok\n",
    "                            # for i in range(total_blocks_components[component_name]):\n",
    "                                # Tambahkan data ke frame_data sesuai dengan indexnya\n",
    "                                # frame_data[f'X{i+1}'] = 0\n",
    "                                # frame_data[f'Y{i+1}'] = 0\n",
    "                                # frame_data[f'Tetha{i+1}'] = 0\n",
    "                                # frame_data[f'Magnitude{i+1}'] = 0\n",
    "                                # # Tambahkan data ke frame_data_all_component sesuai dengan indexnya\n",
    "                                # frame_data_all_component[f'{component_name}-X{i+1}'] = 0\n",
    "                                # frame_data_all_component[f'{component_name}-Y{i+1}'] = 0\n",
    "                                # frame_data_all_component[f'{component_name}-Tetha{i+1}'] = 0\n",
    "                                # frame_data_all_component[f'{component_name}-Magnitude{i+1}'] = 0\n",
    "\n",
    "                            # Append data frame ke list frames_data sesuai dengan component_name\n",
    "                            frames_data[component_name].append(frame_data)\n",
    "                            # Tambahkan kolom \"Folder Path\" dengan nilai folder saat ini\n",
    "                            frame_data['Folder Path'] = 'data_test'\n",
    "                            # Tambahkan kolom \"Label\" dengan nilai label saat ini\n",
    "                            frame_data['Label'] = 'data_test'\n",
    "                            # Set value data_blocks_first_image[component_name] ke data_blocks_image_current\n",
    "                            data_blocks_first_image[component_name] = data_blocks_image_current\n",
    "                            # Skip looping nya ke looping selanjutnya\n",
    "                            continue\n",
    "\n",
    "                        # # Tampilkan data block image current ke matplotlib\n",
    "                        # plt.imshow(np.uint8(data_blocks_image_current), cmap=\"gray\")\n",
    "\n",
    "                        # Inisiasi class POC\n",
    "                        initPOC = POC(data_blocks_first_image[component_name], data_blocks_image_current, blockSize) \n",
    "                        # Pemanggilan fungsi pocCalc() untuk menghitung nilai POC disetiap gambar\n",
    "                        valPOC = initPOC.getPOC() \n",
    "\n",
    "                        # Pemanggilan class dan method untuk menampilkan quiver / gambar panah\n",
    "                        initQuiv = Vektor(valPOC, blockSize)\n",
    "                        quivData = initQuiv.getVektor() \n",
    "\n",
    "                        # plt.quiver(quivData[:, 0], quivData[:, 1], quivData[:, 2], quivData[:, 3], scale=1, scale_units='xy', angles='xy', color=\"r\")    \n",
    "\n",
    "                        # # num = 0\n",
    "                        # for rect_def in valPOC[2]:\n",
    "                        #     x, y, width, height = rect_def\n",
    "                            \n",
    "                        #     rects = patches.Rectangle((x,y), width,height, edgecolor='r', facecolor='none') \n",
    "                        #     plt.gca().add_patch(rects)\n",
    "                            \n",
    "                        #     # plt.text(x,y,f'({num})', color=\"blue\") \n",
    "                        #     # num += 1\n",
    "\n",
    "                        # Pemanggilan class untuk mengeluarkan nilai karakteristik vektor\n",
    "                        # blok ke, x,y,tetha, magnitude, dan quadran ke\n",
    "                        initQuadran = Quadran(quivData) \n",
    "                        quadran = initQuadran.getQuadran()\n",
    "\n",
    "                        # print(tabulate(quadran, headers=['Blok Ke', 'X', 'Y', 'Tetha', 'Magnitude', 'Quadran Ke']))\n",
    "                        # plt.axis('on') \n",
    "                        # plt.show() \n",
    "\n",
    "                        # Update frame_data dengan data quadran\n",
    "                        for i, quad in enumerate(quadran):\n",
    "                            # --- Setup bagian Nilai Fitur Dataset ---\n",
    "                            # Set data kedalam frame_data sesuai column nya\n",
    "                            frame_data[f'X{i+1}'] = quad[1]\n",
    "                            frame_data[f'Y{i+1}'] = quad[2]\n",
    "                            frame_data[f'Tetha{i+1}'] = quad[3]\n",
    "                            frame_data[f'Magnitude{i+1}'] = quad[4]\n",
    "\n",
    "                            # Set data kedalam frame_data_all_component sesuai columnnya\n",
    "                            frame_data_all_component[f'{component_name}-X{i+1}'] = quad[1]\n",
    "                            frame_data_all_component[f'{component_name}-Y{i+1}'] = quad[2]\n",
    "                            frame_data_all_component[f'{component_name}-Tetha{i+1}'] = quad[3]\n",
    "                            frame_data_all_component[f'{component_name}-Magnitude{i+1}'] = quad[4]\n",
    "\n",
    "                            # --- Setup bagian 4qmv Dataset ---\n",
    "                            # Cek apakah quad[5] ada didalam array quadran_dimensions\n",
    "                            if quad[5] in quadran_dimensions:\n",
    "                                # Tambahkan nilai quad[1] ke sumX pada kuadran yang sesuai\n",
    "                                sum_data_by_quadran['sumX'][quad[5]] += quad[1]\n",
    "                                # Tambahkan nilai quad[2] ke sumY pada kuadran yang sesuai\n",
    "                                sum_data_by_quadran['sumY'][quad[5]] += quad[2]\n",
    "                                # Tambahkan nilai quad[3] ke Tetha pada kuadran yang sesuai\n",
    "                                sum_data_by_quadran['Tetha'][quad[5]] += quad[3]\n",
    "                                # Tambahkan nilai quad[4] ke Magnitude pada kuadran yang sesuai\n",
    "                                sum_data_by_quadran['Magnitude'][quad[5]] += quad[4]\n",
    "                                # Tambahkan jumlah quadran sesuai dengan quad[5] ke JumlahQuadran pada kuadran yang sesuai\n",
    "                                sum_data_by_quadran['JumlahQuadran'][quad[5]] += 1\n",
    "                        \n",
    "                        # --- Setup bagian Nilai Fitur Dataset ---\n",
    "                        # Append data frame ke list\n",
    "                        frames_data[component_name].append(frame_data)\n",
    "                        # Tambahkan kolom \"Folder Path\" dengan nilai folder saat ini\n",
    "                        frame_data['Folder Path'] = 'data_test'\n",
    "                        # Tambahkan kolom \"Label\" dengan nilai label saat ini\n",
    "                        frame_data['Label'] = 'data_test'\n",
    "\n",
    "                        # --- Setup bagian 4qmv Dataset ---\n",
    "                        # Inisialisasi data untuk setiap blok dan setiap kuadran dengan nilai sesuai sum_data_by_quadran\n",
    "                        for quadran in quadran_dimensions:\n",
    "                            for feature in frames_data_quadran_column:\n",
    "                                # Buat nama kolom dengan menggunakan template yang diberikan\n",
    "                                column_name = f\"{component_name}_{feature}_{quadran}\"\n",
    "                                # Set value sum_data_by_quadran[feature][quadran] ke frame_data_quadran sesuai column_name nya\n",
    "                                frame_data_quadran[column_name] = sum_data_by_quadran[feature][quadran]\n",
    "\n",
    "                # --- Setup bagian 4qmv Dataset ---\n",
    "                if not index[component_name] == 0:\n",
    "                    # Append data frame ke list frames_data_quadran untuk 4qmv\n",
    "                    frames_data_quadran.append(frame_data_quadran)\n",
    "                    # print(\"Frame Quadran\", frame_data_quadran)\n",
    "                    # Tambahkan kolom \"Folder Path\" dengan nilai folder saat ini\n",
    "                    frame_data_quadran['Folder Path'] = 'data_test'\n",
    "                    # Tambahkan kolom \"Label\" dengan nilai label saat ini\n",
    "                    frame_data_quadran['Label'] = 'data_test'\n",
    "\n",
    "                if not index[component_name] == 0:\n",
    "                    # --- Setup bagian frames data all component Dataset ---\n",
    "                    # Append data frame ke list frames_data_quadran untuk 4qmv\n",
    "                    frames_data_all_component.append(frame_data_all_component)\n",
    "                    # print(\"Frame Quadran\", frame_data_quadran)\n",
    "                    # Tambahkan kolom \"Folder Path\" dengan nilai folder saat ini\n",
    "                    frame_data_all_component['Folder Path'] = 'data_test'\n",
    "                    # Tambahkan kolom \"Label\" dengan nilai label saat ini\n",
    "                    frame_data_all_component['Label'] = 'data_test'\n",
    "\n",
    "                # Update index per component_name\n",
    "                index[component_name] += 1\n",
    "\n",
    "        # Consume Data Ke model joblib\n",
    "        df_fitur_all = pd.DataFrame(frames_data_all_component)\n",
    "        except_feature_columns = ['Frame', 'Folder Path', 'Label']\n",
    "\n",
    "        # Predict and print results with nose\n",
    "        print(\"Predictions with Nose:\")\n",
    "        predict_and_print_results(df_fitur_all.copy(), model_hidung, label_encoder_hidung, except_feature_columns)\n",
    "\n",
    "        # print garis pemisah antar hasil prediksi\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # Predict and print results without nose (remove nose features)\n",
    "        nose_features = [col for col in df_fitur_all.columns if 'hidung' in col]\n",
    "        df_fitur_tanpa_hidung = df_fitur_all.drop(columns=nose_features)\n",
    "\n",
    "        print(\"Predictions without Nose:\")\n",
    "        predict_and_print_results(df_fitur_tanpa_hidung.copy(), model_tanpa_hidung, label_encoder_tanpa_hidung, except_feature_columns)\n",
    "\n",
    "\n",
    "        # hasil pemisah antar file\n",
    "        print(\"\\n\" + \"#\" * 50 + \"\\n\")\n",
    "\n",
    "        # hapus dataframes\n",
    "        del df_fitur_all\n",
    "        del df_fitur_tanpa_hidung\n",
    "        del frames_data_all_component\n",
    "        del frames_data_quadran\n",
    "        del frames_data\n",
    "        del data_blocks_first_image\n",
    "        del index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
