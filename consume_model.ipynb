{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame per second: 200.0\n",
      "Predictions with Nose:\n",
      "Kategori: Happiness, Jumlah: 116, Persentase: 51.33%\n",
      "Kategori: Disgust, Jumlah: 43, Persentase: 19.03%\n",
      "Kategori: Sadness, Jumlah: 19, Persentase: 8.41%\n",
      "Kategori: Surprise, Jumlah: 48, Persentase: 21.24%\n",
      "\n",
      "Hasil Prediksi: Happiness\n",
      "\n",
      "Predictions without Nose:\n",
      "Kategori: Sadness, Jumlah: 17, Persentase: 7.52%\n",
      "Kategori: Happiness, Jumlah: 112, Persentase: 49.56%\n",
      "Kategori: Disgust, Jumlah: 63, Persentase: 27.88%\n",
      "Kategori: Surprise, Jumlah: 34, Persentase: 15.04%\n",
      "\n",
      "Hasil Prediksi: Happiness\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from collections import Counter\n",
    "from helper.helper import format_number_and_round\n",
    "from preprocessing.scarpping_component import extract_component_by_images\n",
    "import os\n",
    "import pandas as pd\n",
    "import dlib\n",
    "import cv2\n",
    "from feature_extraction.poc import POC\n",
    "from feature_extraction.vektor import Vektor\n",
    "from feature_extraction.quadran import Quadran\n",
    "from preprocessing.input_to_image import get_frames_by_input_video\n",
    "\n",
    "# Load the models and label encoders\n",
    "model_hidung = joblib.load('models/knn_model_dengan_hidung.joblib')\n",
    "label_encoder_hidung = joblib.load('models/label_encoder_dengan_hidung.joblib')\n",
    "\n",
    "model_tanpa_hidung = joblib.load('models/knn_model_tanpa_hidung.joblib')\n",
    "label_encoder_tanpa_hidung = joblib.load('models/label_encoder.joblib')\n",
    "\n",
    "# Video directory\n",
    "video_directory = 'dataset/CASME2/CASME2/Happiness/Video_Image_RAW 200fps/12_EP03_04.avi'\n",
    "output_image_directory = 'output_image_5x5'\n",
    "\n",
    "# dapatkan frame dari video\n",
    "fps = cv2.VideoCapture(video_directory).get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(f\"Frame per second: {fps}\")\n",
    "\n",
    "# Convert video to images\n",
    "gambar = get_frames_by_input_video(video_directory, output_image_directory, framePerSecond=fps)\n",
    "\n",
    "components_setup = {\n",
    "    'mulut': {\n",
    "        'object_name': 'mouth',\n",
    "        'object_rectangle': {\"x_right\": 54, \"x_left\": 48, \"y_highest\": 52, \"y_lowest\": 57},\n",
    "        'pixel_shifting': {\"pixel_x\": 25, \"pixel_y\": 5},\n",
    "        'object_dimension': {'width': 140, 'height': 40}\n",
    "    },\n",
    "    'mata_kiri': {\n",
    "        'object_name': 'eye_left',\n",
    "        'object_rectangle': {\"x_right\": 39, \"x_left\": 36, \"y_highest\": 38, \"y_lowest\": 41},\n",
    "        'pixel_shifting': {\"pixel_x\": 25, \"pixel_y\": 25},\n",
    "        'object_dimension': {'width': 90, 'height': 55}\n",
    "    },\n",
    "    'mata_kanan': {\n",
    "        'object_name': 'eye_right',\n",
    "        'object_rectangle': {\"x_right\": 45, \"x_left\": 42, \"y_highest\": 43, \"y_lowest\": 47},\n",
    "        'pixel_shifting': {\"pixel_x\": 25, \"pixel_y\": 25},\n",
    "        'object_dimension': {'width': 90, 'height': 55}\n",
    "    },\n",
    "    'alis_kiri': {\n",
    "        'object_name': 'eyebrow_left',\n",
    "        'object_rectangle': {\"x_right\": 21, \"x_left\": 17, \"y_highest\": 18, \"y_lowest\": 21},\n",
    "        'pixel_shifting': {\"pixel_x\": 15, \"pixel_y\": 15},\n",
    "        'object_dimension': {'width': 110, 'height': 40}\n",
    "    },\n",
    "    'alis_kanan': {\n",
    "        'object_name': 'eyebrow_right',\n",
    "        'object_rectangle': {\"x_right\": 26, \"x_left\": 22, \"y_highest\": 25, \"y_lowest\": 22},\n",
    "        'pixel_shifting': {\"pixel_x\": 15, \"pixel_y\": 15},\n",
    "        'object_dimension': {'width': 110, 'height': 40}\n",
    "    },\n",
    "    'hidung_kanan': {\n",
    "        'object_name': 'nose_right',\n",
    "        'object_rectangle': {\"x_right\": 31, \"x_left\": 40, \"y_highest\": 40, \"y_lowest\": 48},\n",
    "        'pixel_shifting': {\"pixel_x\": 15, \"pixel_y\": -25},\n",
    "        'object_dimension': {'width': 70, 'height': 40}\n",
    "    },\n",
    "    'hidung_kiri': {\n",
    "        'object_name': 'nose_left',\n",
    "        'object_rectangle': {\"x_right\": 47, \"x_left\": 35, \"y_highest\": 47, \"y_lowest\": 54},\n",
    "        'pixel_shifting': {\"pixel_x\": 15, \"pixel_y\": -25},\n",
    "        'object_dimension': {'width': 70, 'height': 40}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize variables for feature extraction\n",
    "blockSize = 5\n",
    "frames_data_all_component = []\n",
    "frames_data_quadran_column = ['sumX', 'sumY', 'Tetha', 'Magnitude', 'JumlahQuadran']\n",
    "quadran_dimensions = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "frames_data = {component_name: [] for component_name in components_setup}\n",
    "total_blocks_components = {component_name: 0 for component_name in components_setup}\n",
    "data_blocks_first_image = {component_name: None for component_name in components_setup}\n",
    "index = {component_name: 0 for component_name in components_setup}\n",
    "\n",
    "# Load face detector and shape predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"models/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Function to calculate the prediction results\n",
    "def get_calculate_from_predict(list_decoded_predictions):\n",
    "    prediction_counts = Counter(list_decoded_predictions)\n",
    "    total_predictions = len(list_decoded_predictions)\n",
    "    result_prediction = None\n",
    "    most_common_count = 0\n",
    "    list_predictions = []\n",
    "\n",
    "    for category, count in prediction_counts.items():\n",
    "        percentage = (count / total_predictions) * 100\n",
    "        list_predictions.append({\n",
    "            \"name\": category,\n",
    "            \"count\": count,\n",
    "            \"percentage\": format_number_and_round(percentage)\n",
    "        })\n",
    "        if count > most_common_count:\n",
    "            most_common_count = count\n",
    "            result_prediction = category\n",
    "\n",
    "    return result_prediction, list_predictions\n",
    "\n",
    "# Process each image\n",
    "for filename in os.listdir(output_image_directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n",
    "        image = cv2.imread(os.path.join(output_image_directory, filename))\n",
    "        image = cv2.resize(image, (600, 500))\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray)\n",
    "\n",
    "        if len(rects) == 0:\n",
    "            print(f\"Skip {filename} karena tidak ada wajah yang terdeteksi\")\n",
    "            continue\n",
    "\n",
    "        for component_name in components_setup:\n",
    "            if index[component_name] != 0:\n",
    "                frame_data_all_component = {'Frame': f\"{index[component_name] + 1}({filename.split('.')[0]})\"}\n",
    "                frame_data_quadran = {'Frame': f\"{index[component_name] + 1}({filename.split('.')[0]})\"}\n",
    "                        \n",
    "        for rect in rects:\n",
    "            shape = predictor(gray, rect)\n",
    "            for component_name, component_info in components_setup.items():\n",
    "                sum_data_by_quadran = {}\n",
    "                frame_data = {'Frame': f\"{index[component_name] + 1}({filename.split('.')[0]})\"}\n",
    "                for column in frames_data_quadran_column:\n",
    "                    sum_data_by_quadran[column] = {quadrant: 0 for quadrant in quadran_dimensions}\n",
    "\n",
    "                data_blocks_image_current = extract_component_by_images(\n",
    "                    image=image,\n",
    "                    shape=shape,\n",
    "                    frameName=filename.split(\".\")[0],\n",
    "                    objectName=component_info['object_name'],\n",
    "                    objectRectangle=component_info['object_rectangle'],\n",
    "                    pixelShifting=component_info['pixel_shifting'],\n",
    "                    objectDimension=component_info['object_dimension']\n",
    "                )\n",
    "\n",
    "                if data_blocks_first_image[component_name] is None:\n",
    "                    frames_data[component_name].append(frame_data)\n",
    "                    frame_data['Folder Path'] = \"data_test\"\n",
    "                    frame_data['Label'] = \"data_test\"\n",
    "                    data_blocks_first_image[component_name] = data_blocks_image_current\n",
    "                    continue\n",
    "\n",
    "                initPOC = POC(data_blocks_first_image[component_name], data_blocks_image_current, blockSize)\n",
    "                valPOC = initPOC.getPOC() \n",
    "\n",
    "                initQuiv = Vektor(valPOC, blockSize)\n",
    "                quivData = initQuiv.getVektor()\n",
    "\n",
    "                initQuadran = Quadran(quivData) \n",
    "                quadran = initQuadran.getQuadran()\n",
    "\n",
    "                for i, quad in enumerate(quadran):\n",
    "                    frame_data[f'X{i+1}'] = quad[1]\n",
    "                    frame_data[f'Y{i+1}'] = quad[2]\n",
    "                    frame_data[f'Tetha{i+1}'] = quad[3]\n",
    "                    frame_data[f'Magnitude{i+1}'] = quad[4]\n",
    "\n",
    "                    frame_data_all_component[f'{component_name}-X{i+1}'] = quad[1]\n",
    "                    frame_data_all_component[f'{component_name}-Y{i+1}'] = quad[2]\n",
    "                    frame_data_all_component[f'{component_name}-Tetha{i+1}'] = quad[3]\n",
    "                    frame_data_all_component[f'{component_name}-Magnitude{i+1}'] = quad[4]\n",
    "\n",
    "                    if quad[5] in quadran_dimensions:\n",
    "                        sum_data_by_quadran['sumX'][quad[5]] += quad[1]\n",
    "                        sum_data_by_quadran['sumY'][quad[5]] += quad[2]\n",
    "                        sum_data_by_quadran['Tetha'][quad[5]] += quad[3]\n",
    "                        sum_data_by_quadran['Magnitude'][quad[5]] += quad[4]\n",
    "                        sum_data_by_quadran['JumlahQuadran'][quad[5]] += 1\n",
    "\n",
    "                frames_data[component_name].append(frame_data)\n",
    "                frame_data['Folder Path'] = \"data_test\"\n",
    "                frame_data['Label'] = \"data_test\"\n",
    "\n",
    "                for quadran in quadran_dimensions:\n",
    "                    for feature in frames_data_quadran_column:\n",
    "                        column_name = f\"{component_name}{feature}{quadran}\"\n",
    "                        frame_data_quadran[column_name] = sum_data_by_quadran[feature][quadran]\n",
    "\n",
    "        if index[component_name] != 0:\n",
    "            frames_data_all_component.append(frame_data_all_component)\n",
    "            frame_data_all_component['Folder Path'] = \"data_test\"\n",
    "            frame_data_all_component['Label'] = \"data_test\"\n",
    "\n",
    "        index[component_name] += 1\n",
    "\n",
    "# Function to predict and print results\n",
    "def predict_and_print_results(df, model, label_encoder, feature_columns):\n",
    "    df = df.drop(columns=feature_columns)\n",
    "    predictions = model.predict(df.values)\n",
    "    decoded_predictions = label_encoder.inverse_transform(predictions)\n",
    "    result_prediction, list_predictions = get_calculate_from_predict(decoded_predictions)\n",
    "    \n",
    "    for pred in list_predictions:\n",
    "        print(f\"Kategori: {pred['name']}, Jumlah: {pred['count']}, Persentase: {pred['percentage']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nHasil Prediksi: {result_prediction}\")\n",
    "\n",
    "df_fitur_all = pd.DataFrame(frames_data_all_component)\n",
    "except_feature_columns = ['Frame', 'Folder Path', 'Label']\n",
    "\n",
    "# Predict and print results with nose\n",
    "print(\"Predictions with Nose:\")\n",
    "predict_and_print_results(df_fitur_all.copy(), model_hidung, label_encoder_hidung, except_feature_columns)\n",
    "\n",
    "# Predict and print results without nose (remove nose features)\n",
    "nose_features = [col for col in df_fitur_all.columns if 'hidung' in col]\n",
    "df_fitur_tanpa_hidung = df_fitur_all.drop(columns=nose_features)\n",
    "\n",
    "print(\"\\nPredictions without Nose:\")\n",
    "predict_and_print_results(df_fitur_tanpa_hidung.copy(), model_tanpa_hidung, label_encoder_tanpa_hidung, except_feature_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\01_EP02_01f.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\02_EP09_01.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\05_EP03_01.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\06_EP01_01.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\09_EP02_01f.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\09_EP05_05.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\09_EP06_02f.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\09_EP09f.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\09_EP15_05.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\12_EP03_04.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\12_EP08_07.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\13_EP03_01.avi with 140.964195094446 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\13_EP09_10.avi with 140.964195094446 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\14_EP09_03.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\14_EP09_04.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\14_EP09_06.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\15_EP03_02.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\16_EP01_05.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\16_EP04_02f.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\17_EP01_06.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\17_EP01_15.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\17_EP03_09.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\17_EP05_02.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\17_EP05_03.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\17_EP06_07.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\17_EP13_09.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\19_EP01_01f.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\19_EP01_02f.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\23_EP02_01.avi with 200.0 FPS\n",
      "Processing dataset/CASME2/CASME2/Happiness\\Video_Image_RAW 200fps\\26_EP03_10.avi with 200.0 FPS\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 145\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m frames_data_quadran_column:\n\u001b[0;32m    143\u001b[0m     sum_data_by_quadran[column] \u001b[38;5;241m=\u001b[39m {quadrant: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m quadrant \u001b[38;5;129;01min\u001b[39;00m quadran_dimensions}\n\u001b[1;32m--> 145\u001b[0m data_blocks_image_current \u001b[38;5;241m=\u001b[39m \u001b[43mextract_component_by_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframeName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjectName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomponent_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobject_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjectRectangle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomponent_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobject_rectangle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixelShifting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomponent_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpixel_shifting\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjectDimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomponent_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobject_dimension\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_blocks_first_image[component_name] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m     frames_data[component_name]\u001b[38;5;241m.\u001b[39mappend(frame_data)\n",
      "File \u001b[1;32md:\\PCVK-DLIB-KNN\\preprocessing\\scarpping_component.py:61\u001b[0m, in \u001b[0;36mextract_component_by_images\u001b[1;34m(image, shape, frameName, objectName, objectRectangle, pixelShifting, objectDimension)\u001b[0m\n\u001b[0;32m     56\u001b[0m height_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(objectDimension[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m], image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m y_highest)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# print(f\"width_object: {width_object}, height_object: {height_object}\")\u001b[39;00m\n\u001b[0;32m     60\u001b[0m block_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m---> 61\u001b[0m     \u001b[43mextract_component_as_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframeName\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43my_highest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_left\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwidth_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_highest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mheight_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_left\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjectName\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m )\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m block_data\n",
      "File \u001b[1;32md:\\PCVK-DLIB-KNN\\preprocessing\\extract_to_image.py:25\u001b[0m, in \u001b[0;36mextract_component_as_image\u001b[1;34m(image, frameNumber, objectRectangle, objectName)\u001b[0m\n\u001b[0;32m     22\u001b[0m file_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/component_to_images/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobjectName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframeNumber\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Create directory if it doesn't exist\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m y_top, x_right, y_bottom, x_left \u001b[38;5;241m=\u001b[39m objectRectangle\n\u001b[0;32m     29\u001b[0m width_object \u001b[38;5;241m=\u001b[39m x_right \u001b[38;5;241m-\u001b[39m x_left\n",
      "File \u001b[1;32m<frozen os>:213\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[1;32m<frozen genericpath>:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from collections import Counter\n",
    "import os\n",
    "import pandas as pd\n",
    "import dlib\n",
    "import cv2\n",
    "from helper.helper import format_number_and_round\n",
    "from preprocessing.scarpping_component import extract_component_by_images\n",
    "from feature_extraction.poc import POC\n",
    "from feature_extraction.vektor import Vektor\n",
    "from feature_extraction.quadran import Quadran\n",
    "from preprocessing.input_to_image import get_frames_by_input_video\n",
    "\n",
    "# Load the models and label encoders\n",
    "model_hidung = joblib.load('models/knn_model_dengan_hidung.joblib')\n",
    "label_encoder_hidung = joblib.load('models/label_encoder_dengan_hidung.joblib')\n",
    "\n",
    "model_tanpa_hidung = joblib.load('models/knn_model_tanpa_hidung.joblib')\n",
    "label_encoder_tanpa_hidung = joblib.load('models/label_encoder.joblib')\n",
    "\n",
    "# Emotions directories\n",
    "emotions = ['Happiness', 'Disgust', 'Sadness', 'Surprise']\n",
    "base_directory = 'dataset/CASME2/CASME2/'\n",
    "\n",
    "output_image_directory = 'output_image_5x5'\n",
    "components_setup = {\n",
    "    'mulut': {\n",
    "        'object_name': 'mouth',\n",
    "        'object_rectangle': {\"x_right\": 54, \"x_left\": 48, \"y_highest\": 52, \"y_lowest\": 57},\n",
    "        'pixel_shifting': {\"pixel_x\": 25, \"pixel_y\": 5},\n",
    "        'object_dimension': {'width': 140, 'height': 40}\n",
    "    },\n",
    "    'mata_kiri': {\n",
    "        'object_name': 'eye_left',\n",
    "        'object_rectangle': {\"x_right\": 39, \"x_left\": 36, \"y_highest\": 38, \"y_lowest\": 41},\n",
    "        'pixel_shifting': {\"pixel_x\": 25, \"pixel_y\": 25},\n",
    "        'object_dimension': {'width': 90, 'height': 55}\n",
    "    },\n",
    "    'mata_kanan': {\n",
    "        'object_name': 'eye_right',\n",
    "        'object_rectangle': {\"x_right\": 45, \"x_left\": 42, \"y_highest\": 43, \"y_lowest\": 47},\n",
    "        'pixel_shifting': {\"pixel_x\": 25, \"pixel_y\": 25},\n",
    "        'object_dimension': {'width': 90, 'height': 55}\n",
    "    },\n",
    "    'alis_kiri': {\n",
    "        'object_name': 'eyebrow_left',\n",
    "        'object_rectangle': {\"x_right\": 21, \"x_left\": 17, \"y_highest\": 18, \"y_lowest\": 21},\n",
    "        'pixel_shifting': {\"pixel_x\": 15, \"pixel_y\": 15},\n",
    "        'object_dimension': {'width': 110, 'height': 40}\n",
    "    },\n",
    "    'alis_kanan': {\n",
    "        'object_name': 'eyebrow_right',\n",
    "        'object_rectangle': {\"x_right\": 26, \"x_left\": 22, \"y_highest\": 25, \"y_lowest\": 22},\n",
    "        'pixel_shifting': {\"pixel_x\": 15, \"pixel_y\": 15},\n",
    "        'object_dimension': {'width': 110, 'height': 40}\n",
    "    },\n",
    "    'hidung_kanan': {\n",
    "        'object_name': 'nose_right',\n",
    "        'object_rectangle': {\"x_right\": 31, \"x_left\": 40, \"y_highest\": 40, \"y_lowest\": 48},\n",
    "        'pixel_shifting': {\"pixel_x\": 15, \"pixel_y\": -25},\n",
    "        'object_dimension': {'width': 70, 'height': 40}\n",
    "    },\n",
    "    'hidung_kiri': {\n",
    "        'object_name': 'nose_left',\n",
    "        'object_rectangle': {\"x_right\": 47, \"x_left\": 35, \"y_highest\": 47, \"y_lowest\": 54},\n",
    "        'pixel_shifting': {\"pixel_x\": 15, \"pixel_y\": -25},\n",
    "        'object_dimension': {'width': 70, 'height': 40}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize variables for feature extraction\n",
    "blockSize = 5\n",
    "frames_data_all_component = []\n",
    "frames_data_quadran_column = ['sumX', 'sumY', 'Tetha', 'Magnitude', 'JumlahQuadran']\n",
    "quadran_dimensions = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "frames_data = {component_name: [] for component_name in components_setup}\n",
    "total_blocks_components = {component_name: 0 for component_name in components_setup}\n",
    "data_blocks_first_image = {component_name: None for component_name in components_setup}\n",
    "index = {component_name: 0 for component_name in components_setup}\n",
    "\n",
    "# Load face detector and shape predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"models/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "result_list = []\n",
    "\n",
    "# Function to calculate the prediction results\n",
    "def get_calculate_from_predict(list_decoded_predictions):\n",
    "    prediction_counts = Counter(list_decoded_predictions)\n",
    "    total_predictions = len(list_decoded_predictions)\n",
    "    result_prediction = None\n",
    "    most_common_count = 0\n",
    "    list_predictions = []\n",
    "\n",
    "    for category, count in prediction_counts.items():\n",
    "        percentage = (count / total_predictions) * 100\n",
    "        list_predictions.append({\n",
    "            \"name\": category,\n",
    "            \"count\": count,\n",
    "            \"percentage\": format_number_and_round(percentage)\n",
    "        })\n",
    "        if count > most_common_count:\n",
    "            most_common_count = count\n",
    "            result_prediction = category\n",
    "\n",
    "    return result_prediction, list_predictions\n",
    "\n",
    "# Process each image\n",
    "for emotion in emotions:\n",
    "    emotion_directory = os.path.join(base_directory, emotion, 'Video_Image_RAW 200fps')\n",
    "    for root, _, files in os.walk(emotion_directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".avi\"):\n",
    "                video_path = os.path.join(root, file)\n",
    "                \n",
    "                # Convert video to images\n",
    "                fps = cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FPS)\n",
    "                print(f\"Processing {video_path} with {fps} FPS\")\n",
    "                images = get_frames_by_input_video(video_path, output_image_directory, framePerSecond=fps)\n",
    "\n",
    "                for filename in os.listdir(output_image_directory):\n",
    "                    if filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n",
    "                        image = cv2.imread(os.path.join(output_image_directory, filename))\n",
    "                        image = cv2.resize(image, (600, 500))\n",
    "                        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                        rects = detector(gray)\n",
    "\n",
    "                        if len(rects) == 0:\n",
    "                            print(f\"Skip {filename} karena tidak ada wajah yang terdeteksi\")\n",
    "                            continue\n",
    "\n",
    "                        for component_name in components_setup:\n",
    "                            if index[component_name] != 0:\n",
    "                                frame_data_all_component = {'Frame': f\"{index[component_name] + 1}({filename.split('.')[0]})\"}\n",
    "                                frame_data_quadran = {'Frame': f\"{index[component_name] + 1}({filename.split('.')[0]})\"}\n",
    "\n",
    "                        for rect in rects:\n",
    "                            shape = predictor(gray, rect)\n",
    "                            for component_name, component_info in components_setup.items():\n",
    "                                sum_data_by_quadran = {}\n",
    "                                frame_data = {'Frame': f\"{index[component_name] + 1}({filename.split('.')[0]})\"}\n",
    "                                for column in frames_data_quadran_column:\n",
    "                                    sum_data_by_quadran[column] = {quadrant: 0 for quadrant in quadran_dimensions}\n",
    "\n",
    "                                data_blocks_image_current = extract_component_by_images(\n",
    "                                    image=image,\n",
    "                                    shape=shape,\n",
    "                                    frameName=filename.split(\".\")[0],\n",
    "                                    objectName=component_info['object_name'],\n",
    "                                    objectRectangle=component_info['object_rectangle'],\n",
    "                                    pixelShifting=component_info['pixel_shifting'],\n",
    "                                    objectDimension=component_info['object_dimension']\n",
    "                                )\n",
    "\n",
    "                                if data_blocks_first_image[component_name] is None:\n",
    "                                    frames_data[component_name].append(frame_data)\n",
    "                                    frame_data['Folder Path'] = os.path.join(emotion_directory, filename)\n",
    "                                    frame_data['Label'] = emotion\n",
    "                                    data_blocks_first_image[component_name] = data_blocks_image_current\n",
    "                                    continue\n",
    "\n",
    "                                initPOC = POC(data_blocks_first_image[component_name], data_blocks_image_current, blockSize)\n",
    "                                valPOC = initPOC.getPOC() \n",
    "\n",
    "                                initQuiv = Vektor(valPOC, blockSize)\n",
    "                                quivData = initQuiv.getVektor()\n",
    "\n",
    "                                initQuadran = Quadran(quivData) \n",
    "                                quadran = initQuadran.getQuadran()\n",
    "\n",
    "                                for i, quad in enumerate(quadran):\n",
    "                                    frame_data[f'X{i+1}'] = quad[1]\n",
    "                                    frame_data[f'Y{i+1}'] = quad[2]\n",
    "                                    frame_data[f'Tetha{i+1}'] = quad[3]\n",
    "                                    frame_data[f'Magnitude{i+1}'] = quad[4]\n",
    "\n",
    "                                    frame_data_all_component[f'{component_name}-X{i+1}'] = quad[1]\n",
    "                                    frame_data_all_component[f'{component_name}-Y{i+1}'] = quad[2]\n",
    "                                    frame_data_all_component[f'{component_name}-Tetha{i+1}'] = quad[3]\n",
    "                                    frame_data_all_component[f'{component_name}-Magnitude{i+1}'] = quad[4]\n",
    "\n",
    "                                    if quad[5] in quadran_dimensions:\n",
    "                                        sum_data_by_quadran['sumX'][quad[5]] += quad[1]\n",
    "                                        sum_data_by_quadran['sumY'][quad[5]] += quad[2]\n",
    "                                        sum_data_by_quadran['Tetha'][quad[5]] += quad[3]\n",
    "                                        sum_data_by_quadran['Magnitude'][quad[5]] += quad[4]\n",
    "                                        sum_data_by_quadran['JumlahQuadran'][quad[5]] += 1\n",
    "\n",
    "                                frames_data[component_name].append(frame_data)\n",
    "                                frame_data['Folder Path'] = \"data_test\"\n",
    "                                frame_data['Label'] = video_path\n",
    "\n",
    "                                for quadran in quadran_dimensions:\n",
    "                                    for feature in frames_data_quadran_column:\n",
    "                                        column_name = f\"{component_name}{feature}{quadran}\"\n",
    "                                        frame_data_quadran[column_name] = sum_data_by_quadran[feature][quadran]\n",
    "\n",
    "                        if index[component_name] != 0:\n",
    "                            frames_data_all_component.append(frame_data_all_component)\n",
    "                            frame_data_all_component['Folder Path'] = \"data_test\"\n",
    "                            frame_data_all_component['Label'] = \"data_test\"\n",
    "\n",
    "                        index[component_name] += 1\n",
    "\n",
    "# Function to predict and print results\n",
    "def predict_and_print_results(df, model, label_encoder, feature_columns, description):\n",
    "    dir = df['Folder Path'].values[0]\n",
    "    predictions = model.predict(df[feature_columns].values)\n",
    "    decoded_predictions = label_encoder.inverse_transform(predictions)\n",
    "    result_prediction, list_predictions = get_calculate_from_predict(decoded_predictions)\n",
    "    \n",
    "    print(f\"\\n{description} (Direktori: {dir}):\")\n",
    "    for pred in list_predictions:\n",
    "        print(f\"  Kategori: {pred['name']}, Jumlah: {pred['count']}, Persentase: {pred['percentage']:.2f}%\")\n",
    "    print(f\"Hasil Prediksi: {result_prediction}\")\n",
    "\n",
    "# Dataframe preparation\n",
    "df_fitur_all = pd.DataFrame(frames_data_all_component)\n",
    "except_feature_columns = ['Frame', 'Folder Path', 'Label']\n",
    "feature_columns = df_fitur_all.columns.difference(except_feature_columns)\n",
    "\n",
    "# Predict and print results with nose\n",
    "print(\"Predictions with Nose:\")\n",
    "predict_and_print_results(df_fitur_all.copy(), model_hidung, label_encoder_hidung, feature_columns, \"Prediksi dengan hidung\")\n",
    "\n",
    "# Predict and print results without nose (remove nose features)\n",
    "nose_features = [col for col in df_fitur_all.columns if 'hidung' in col]\n",
    "df_fitur_tanpa_hidung = df_fitur_all.drop(columns=nose_features)\n",
    "\n",
    "print(\"\\nPredictions without Nose:\")\n",
    "predict_and_print_results(df_fitur_tanpa_hidung.copy(), model_tanpa_hidung, label_encoder_tanpa_hidung, feature_columns.difference(nose_features), \"Prediksi tanpa hidung\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
